- 빅 데이터
    - 제타바이트, 요타바이트를 넘어 새로운 단위 필요
- 데이터 마이닝
    - 빅데이터에서 추출 가능한, 잠재적 가치가 있는 정보와 통찰력을 찾는 과정
- 인공지능과 머신러닝
- 개인정보 유출 등

# 082 제타바이트 시대

- 컴퓨터로 어떤 활동을 하던 간에 데이터가 생성됨
- 웹에서 검색, 클릭 등을 하면 개인 데이터 하나하나가 모두 수집됨
- 2021년에는 연간 전 세계 인터넷 트래픽이 3제타바이트를 초과함

# 083 검색 엔진과 타깃 광고

- 검색은 주요 대규모 사업.
- 검색 엔진의 작동 원리
    - 사용자가 웹페이지 폼에 쿼리를 입력하고 서버로 보내면
    - 서버는 링크과 텍스트 조각의 목록을 반환함
        - 쿼리 단어를 포함하는 페이지 목록을 생성하고, 관련도 순으로 정렬한 후, 페이지 텍스트 조각을 HTML로 감싸는 작업 포함
    - 사용자 쿼리마다 웹 전체를 새로 검색하기에는 웹은 너무 크기 때문에, 페이지 정보를 미리 서버에 저장하고 구조화 하여 웹 크롤링을 통해 쿼리에 답할 준비를 해놓음.
        - 관련 있는 내용들을 DB에 저장하여, 신속하게 응답할 수 있도록 한다
    - 규모가 엄청 크기 때문에, 적절한 알고리즘이 필요하다
    - 크롤링 처리, 인덱스 구축, 쿼리 응답 만들기
- 초기 검색 엔진은 단순히 검색어가 포함된 페이지 목록만들 표시했음, 웹이 커질수록 관련성 없는 페이지들이 섞이게 됨.
    - 구글은 이를 위해 페이지랭크 알고리즘 도입. 각 페이지 별로 품질 측정값을 할당함
- 광고 수익으로 비용 마련
    - 페이지 뷰, 클릭, 전환의 측면에서 결정됨
    - 광고주는 특정 검색어에 대한 검색 결과 옆에 광고를 표시할 권리를 얻고자 입찰에 참여하고, 광고 회사는 사용자가 광고를 클릭하면 수익을 얻음
    - 구글 애즈로 시험 가능
    - 광고주가 비용을 지불해서 검색 결과를 자신에게 유리한 방향으로 치우치게 할 수는 없음.
    - 명목상 중립적인 광고의 결과가 인종, 종교 또는 민족에 관한 프로파일링을 기반으로 미묘하게 특정 그룹에 유리하게 치우칠 수 도 있음.
- 덕덕고 : 개인정보 추적하지 않는 웹 검색 페이지

# 084 내가 인터넷을 보면 인터넷도 나를 본다

- 쿠키, 웹 버그, 자바스크립트, 브라우저 핑거프린팅 등을 통해 사용자를 추적할 수 있음
- 지오 태깅(geo-tagging) : 일부 디지털 카메라, 스마트폰에서는 GPS가 포함되어있어서 찍은 사진 각각에 지리적 위치를 인코딩 할 수 있음.
- 광고를 위해 더 정확한 타게팅을 위해 정보를 사용한다고 주장하지만, 훨씬 불순한 목적으로도 사용할 수 있음.
- 정보는 어떻게 수집될까?
    - 브라우저에서 만들어지는 요청과 함께 특정 정보가 자동으로 전송 됨. IP 주소, 보고 있던 페이지, 브라우저 유형과 버전, 운영체제, 언어 설정 등
    - 서버에서 온 쿠키가 있다면 그 쿠키도 전송 됨.
    - 웹 비콘을 통해서 내가 특정 페이지를 보고 있다는 사실을 알 수 있음.
        - 또한 요청한 시각을 통해 내가 언제 메일을 확인했는지 확인 가능
    - 자바스크립트를 통해 마우스 위치, 블록 선택, 클릭 여부 등 자세히 알 수 있음
- 브라우저 핑거프린팅(browswer fingerprinting) : 브라우저의 개별 특성을 사용하여 쿠키 없이도 사용자를 식별하는 기법. 운영체제, 브라우저 종류, 버전, 언어 설정, 설치된 글꼴과 플러그인 등을 통해 특징적인 정보 제공.
- ISP에서는 심층 패킷 검사(deep packet inspection)을 통해 패킷을 검사하고, 이를 수정하기도 함.
    - 이를 방지하기 위해선 HTTPS를 이용하여 종단 간 암호화 하는 것이 필요함.
        - 그러나 HTTPS도 출발지와 목적지 같은 메타 데이터는 숨겨주지 않음.

# 085 트윗을 올리기 전에

- SNS는 자발적으로 프라이버시를 포기하는 것
- SNS의 비즈니스 모델은 다량의 사용자 정보를 수집하고, 이를 광고주에게 판매하는 것.
    - 필연적으로 프라이버시 침해 문제가 발생할 수 밖에 없음
- 페이스북의 연 매출 700억 달러는 거의 전부 광고.
    - 서비스가 급격한 성장세를 이루는 경우, 각종 정책을 신중히 고려할 시간이 부족하고, 보안 면에서 견고한 컴퓨터 프로그램을 여유롭게 개발하기도 어려움.
- 지오로케이션(geoloaction) 서비스는 사용자의 위치를 휴대전화로 표시하여 친구를 직접 만나거나, 위치 기반 게임을 하기 쉽게 함
- 매장 내 비콘(in-store beacon). 블루투스를 사용하여 휴대전화 앱과 통신하는 비콘이 매장 내에서 사용자의 위치를 모니터링하고, 특정 상품에 관심이 있는 것 같으면 구매를 권함
- 위치 프라이버시(loaction privacy) : 자신의 위치를 비공개로 유지할 권리는 점점 더 어러워짐
- 메타데이터만으로도 많은 것들을 알아 낼 수 있음
    - 누가 누구와 통화했는지, SNS에서 어떤 게시글에 좋아요를 눌렀는지, 어떤 페이지에 오래 머물렀는 지 등
- 페이스북은 얼굴 인식 기능을 통해 태깅을 하고있음.

# 086 메타데이터에 관한 불편한 진실

- 인터넷과 웹은 사람들이 정보를 수집하고, 저장하고, 제공하는 방법에 혁신을 일으킴
- 엄청난 양의 데이터(빅데이터)는 많은 유용한 서비스의 원료가 됨
- 이전의 공공 데이터들은 약간의 노력이 필요했지만, 현재는 너무나 쉽게 구할 수 있음
- 검색 엔진은 로그를 얼마나 보유해야하는가?
    - 프라이버시 보호를 위해서 단기간 vs 법 집행을 위해 장기간
- 재식별화 문제(re-identfication) : 비식별화된 개인정보를 다른 정보와 조합, 분석 또는 처리를 통해 특정 개인을 다시 식별할 수 있게 하는 일련의 과정 또는 방법

# 087 클라우드와 프라이버시

- 기존의 프로그램은 데이터가 개인이 소유한 컴퓨터에 존재했음
- 클라우드 컴퓨팅(Cloud computing)
    - 브라우저나 휴대전화를 사용하여 인터넷 서버에 저장된 정보에 접근하고 조작하는 방식
    - 컴퓨터에서 실행되지만, 일부 서비스를 사용하려면 인터넷이 필요
    - 데이터는 로컬에 저장되지 않고, 클라우드 즉 서비스 제공업체에 저장됨
    - 개인용 컴퓨터 성능이 더 강력해짐에 따라 브라우저 성능도 높아짐
    - 대부분의 클라이언트와 서버 간 대역폭과 레이턴시가 10년 전보다 훨씬 나아져서 이제는 데이터를 빨리 보내고 받을 수 있음
    - 브라우저는 사용자 인터페이스 작업을 대부분 처리할 수 있게 되었으며, 대량의 데이터를 유지하고 대량 연산을 수행할 때 서버를 사용함
    - 클라이언트 측의 빠른 처리 능력과 충분한 메모리, 서버로 연결되는 높은 대역폭이 필요함
    - 사용자 동작과 같은 콘텐츠 업데이트 같은 서버 동작에 반응하여 그래픽 요소를 신속히 업데이터하고 표시하도록 많은 요쳥을 함
    - 브라우저와 자바스크립트 버전 간의 호환성 문제도 있음
    - 서버와 브라우저 어느 쪽에서 계산을 수행하고 정보를 처리하는 것이 유리할지 트레이트 오프
        - 웹페이지 콘텐츠가 압축되지 않은 상태로 전송 된다면, 서버와 클라이언트에서 처리할 일은 줄어들지만 대역폭이 더 많이 필요. 반대로 압축된 상태라면 대역폭은 덜 필요하지만, 서버와 클라이언트가 할일이 많아짐
- 클라우드 컴퓨팅의 프라이버시 문제
    - 프라이버시는 사용자와 업체 간의 문제
    - 정부의 정보 공개에 저항할 수 있는가?
- 프로톤 메일(Proton Mail) : 스위스에서 서비스를 운영하고, 프라이버시를 보장하는 메일 서비스
- 클라우드 서비스 종류
    - Iaas(Infrastructure as a Service) : 인프라로서 서비스 제공. EC2, S3 등
    - Paas(Platform as a Service) : 서비스를 개발할 수 있는 환경 제공. 구글의 앱 엔진 등
    - Saas(Software as a Service) : 클라우드 기반의 응용프로그램을 서비스 형태로 제공. 구글 드라이브 등

# 088 요약

- 디지털 기술을 사용할 때 방대하면서도 상세한 데이터 흐름이 생성됨.
- 데이터는 모두 상업적인 용도로 수집되어, 인식하는 것 보다 훨씬 더 많이 공유되고, 결합되고, 연구되고, 판매됨
- 대중의 데이터 수집 범위 고려 인식이 점점 더 높아지고 있음
- 데이터는 또한 정부가 사용할 목적으로 수집되는데, 장기적으로는 더 해로워 보임
- 인터넷은 어딘가에 쉽게 연결할 수 있게 해주지만, 원치 않는 연결도 생길 수 있음에 주의할 것

# 089 인간의 영역에 들어온 컴퓨터

- 인공지능의 역사적인 근원은 1950년대
- 실제로 효과를 발휘하기 시작한 것은 비교적 최근의 일
- 영상 인식 시스템 : 사진의 구성 요소를 분리하고, 인식하는데 효과적.
- 인공 지능(Artificial Intelligence, AI) : 인간만 할 수 있다고 생각하는 일을 컴퓨터를 사용해서 하는 것을 포괄하는 개념
- 머신 러닝(Machine  Learning : ML) : 인공 지능의 부분 집합. 알고리즘을 훈련하는데 사용되는 광범위한 기술 군을 일컫음. 이러한 훈련을 통해 알고리즘이 자체적으로 결정을 내려서, AI라고 불리는 과제를 수행하도록 함
    - 머신러닝과 통계는 겹치는 부분이 있지만 같지는 않음.
    - 통계는 어떤 데이터를 만드는 메커니즘을 설명하는 모델을 가정하고, 데이터에 가장 적합한 모델에 대한 매개변수를 찾음
    - 머신러닝은 시스템은 모델을 가정하지 않고 데이터에서 나타나는 관계를 찾음.
    - 머신러닝 시스템은 통계보다 더 큰 데이터엣에 적용됨
- 딥 러닝(Deep Learning, DL) : 머신 러닝의 특정한 형태, 인간의 뇌에 있는 신경망과 유사한 계산 모델 사용. 컴퓨터 비전 분야에서 뛰어난 성과를 보임.

# 090 인공지능의 겨울

- 컴퓨터의 개발 초기였던 20세기 중반, 게임이나 번역과 같은 과제 수행에 집중
- 1950, 60년대의 인공지능 연구는 낙관적이였으나, 실제로는 연구가 생각했던것 보다 훨씬 더 어려운 것으로 밝혀짐.
    - 이후, 10~20년간 침체기를 겪었는데, 이때를 ‘AI’의 겨울이라고 불림
- 1980, 90년대에는 전문가 시스템(Expert System), 또는 규칙 기반 시스템(rule-based system)에 대한 연구가 시작됨
    - 해당 분야의 전문가가 다량의 규칙을 작성하고, 프로그래머가 그 규칙을 코드로 변환하면, 컴퓨터가 그 코드를 적용해 과제를 수행하는 방법.
    - 의료 진단분야, 고객 지원, 기계 시스템의 유지와 수리, 기타 중점 연구 분야에서 실질적인 성공을 거두었으나 결국 중대한 제약이 있음이 분명해짐
    - 실제로 모든 고려사항을 종합한 규칙 집합은 모으기가 어렵고, 예외가 너무 많음.
    - 더 큰 주제나 새로운 문제로 확장하기도 어렵고, 조건이 바뀌거나 문제 이해 수준이 높아지면 컴퓨터에게 알려줄 규칙도 계속해서 업데이트 되어야함.

# 091 머신러닝의 학습 알고리즘

- 특정 문제 해결을 위해 미리 규칙을 제공하거나 명시적으로 프로그래밍하지 않은 상태에서, 알고리즘에 많은 예를 주고 스스로 학습하도록 하는 것
- 가장 단순한 형태는 훈련 집합(training set)을 프로그램에 제공하는 것.
    - 이 훈련 집합은 적절한 레이블이 붙은 데이터로 구성 됨
- 지도 학습(supervised learning)
    - 올바른 범주로 레이블이 지정되거나 정확한 값이 주어진 많은 데이터를 처리하는 구조
    - ex) 스팸 여부, 동물 구분, 등
    - 어떤 특징이 올바른 결정을 내리는데 중요한 특징인지 알려 주어야함.
    - 손 글씨 숫자 인식이 대표적인 문제. MNIST 데이터베이스 이용
    - 분류(classification) : 항목들을 적합한 그룹으로 넣는 작업
    - 예측(prediction) 알고리즘 : 데이터를 보고 다음 올 어떤 숫자 값을 예측하는데 사용
- 비지도 학습(unsupervised learning) : 레이블 없는 훈련 데이터, 즉 어떤 이름이나 값으로 레이블이 지정되지 않은 데이터로 학습.
    - 데이터에서 패턴이나 구조를 찾고, 도출한 특징을 바탕으로 그룹화.
    - 가장 대표적인 학습이 k-평균 군집화 알고리즘(k-means clustering algorithm)
        - 같은 그룹 내의 항목 간 유사도는 극대화 하는 동시에 다른 그룹과의 유사도는 최소화 하는 방식으로 데이터를 k개의 그룹에 나눠서 할당
    - 데이터 항목의 특정 그룹에 있는 데이터 중 이상치를 식별하는데 유용함
    - 레이블이 지정된 훈련 데이터가 필요하지 않아 비용이 많이 들지 않지만, 모든 상황에서 그런 것은 아님.
- 머신러닝 알고리즘의 실패 방식들
    - 오버 피팅(over-fitting) : 훈련 데이터에는 좋은 성능을 보이지만, 새로운 데이터에는 성능이 떨어지는 현상
    - 알고리즘이 훈련 데이터에 편향을 강화하는 결과

    # 092 인간 뇌를 모방한 신경망과 딥 러닝

- 컴퓨터가 인간 뇌의 작동 방식을 모방할 수 있다면 지능이 피룡한 과제에서 인간만큼 훌륭한 성능을 낼 수 있을 것이다 → 인공지능의 시작
- 컴퓨터 신경망은 뉴런의 연결 구조를 단순화 한 버전으로, 일정한 패턴으로 연결된 인공 뉴런을 기초로 함.
    - 각 간선을 따라 전달되는 데이터에 적용되는 가중치가 있음
- 2000년대 초반에는 인공 신경망이 영상 인식 같은 과제에서 기존 가장 우수했던 기법보다 더 나은 결과를 보이기 시작함
- 작동 원리
    - 먼저 초기 계층이 저수준 특징을 식별함
    - 이후 계층은 물체나 색상 영역같은 고수준 특징을 식별하며, 마지막으로 최종 계층이 고양이나 얼굴 같은 개체를 식별함.
    - 계층의 수는 알고리즘에 따라 2~3개일수도 있고, 수십개일수도 있음.
    - 또한 신경망에서 정보는 순방향 뿐만 아니라 역방향으로도 흘러가서, 신경망 처리를 반복하고 각 노드에서 가중치를 업데이트함으로써 각 계층의 인식 성능을 개선함
    - 반복할 때마다 알고리즘은 신경망이 처리를 수행한 결과와 우리가 원하는 결과 사이의 오차를 측정하고, 다음 반복 시 오차를 줄이고자 가중치를 조정함
- 찾아야할 특징 집합이 주어지지 않아도 됨. 알아서 특징들을 찾으며, 이 과정도 학습의 일부임
    - 신경망들은 자신들이 식별한 ‘특징’들이 무엇인지를 설명하지 않으며, 결과에 대해 구체적인 설명이나 근거를 제공하지 않으므로 주의해야함
- 구글 스트리트 뷰에 주택 번호나 자동차 번호판, 얼굴들을 자동으로 흐리게 만들어줌.
- 로봇 공학 응용 분야의 핵심 기술
- 얼굴 인식 기술은 개인의 프라이버시에 매우 위험한 기술임
- 강화학습 : 외부환경에서 오는 피드백을 통해 계속해서 자신의 성능을 개선함. 알파제로

 

# 093 인공지능과 사람이 쓴 시를 구별할 수 있을까?

- 자연어 처리(natural language processing) : 머신러닝의 하위 분야, 컴퓨터가 인간의 언어를 처리하게 하는 방법을 다룸
    - 어떤 텍스트가 주어졌을 때 그 의미가 무엇인지 이해하고, 내용을 요약하고, 다른 언어로 번역하고, 음성으로 변환하며, 심지어 사람이 작성한 것 처럼 보이는 의미 있는 텍스트를 생성하기도 함
- 감정 분석(sentiment analysis) : 텍스트가 기본적으로 긍정, 부정인지를 판별.
    - 단순 부정, 반어법과 비꼬기 등 매우 어려운 구분
- 튜링테스트
- 자연어를 이용한 컴퓨터 소통 중 초기 시도 : 일라이자 프로그램
- 음성 인식 소프트웨어
- 기계 번역
    - ‘the spirit is willing but the flesh is weak’ 영어 → 러시아어 → 영어

# 094 요약

- 인공지능과 머신러닝은 컴퓨터 비전, 음성 인식과 생성, 자연어 처리, 로봇 공학, 이외 다른 많은 영역에서 획기적인 발전을 가져옴.
- 동시에 공정성, 편향성, 책임 소재, 적절한 윤리적 사용 문제에 관한 심각한 우려를 불러 일으킴
    - 훈련 데이터에 존재하는 부수적 요소 때문에 머신러닝 알고리즘이 잘못된 방향으로 학습할 가능성도 있음.
    - 머신러닝 알고리즘이 자신이 학습했던 데이터보다 더 나은 결과를 내놓을 수 있을까?
- 컴퓨터 비전 시스템은 다양한 감시 시나리오에 사용됨
    - 이런 종류의 결정을 기계화 하는 것을 어디까지 허용해야 하는가
    - 안전 필수 시스템에서 머신러닝을 어떻게 다뤄야 할까?

# 095 숨길 게 없다면 괜찮을까?

- 디지털 기술은 삶은 윤택하기 만들었지만, 동시에 개인의 프라이버시와 보안에 크게 부정적인 영향을 주었음
- 프라이버시는 한 사람의 개인적 삶의 여러 측면이 타인에게 알려지지 않도록 하는 권리와 능력
    - 내 개인적인 일들은 내가 명시적으로 허락할 때만 다른 사람이 알 수 있어야 함
    - 보통 사람들에 비해 알려지만 곤란한 비밀이 많다는 뜻이 아니라, 기본적으로 자기 생활과 습관이 타인에게 공유되지 않음을 알고 안심할 수 있어야 한다는 뜻.
    - 특히나 사업 관계자, 또는 접근 의도와 무관하게 정부 기관에 공유되지 않아야함
- 보안은 단어 사용 주체에 따라 달라짐
    - 정부에게는 국가 안보, 기업에게는 범죄자나 다른 기업으로부터, 개인에게는 프라이버시

# 096 둘이서만 공유하는 비밀 키 암호 기법

- 암호 기법(cryptography) : 프라이버시 침해 공격에 대한 최선의 방어책
- 가장 간단한 암호화 방식. 카이사르 암호
- 암호 기법의 역사
    - 스코틀랜드 여왕 메리
    - 2차 세계 대전 에니그마 기계
- 암호 기법의 기본 아이디어. 메세지를 변형했다가 복원할 수 있도록 일정하게 공유된 키 이용.
    - 카이사르 암호화는 알파벳을 3번 이동
    - 에니그마 기계에서는 여러개의 코드 휠 설정과 한 벌의 플러그 배선 이용
- 공격 방법
    - 각 기호의 출현 횟수를 세는 빈도 분석(frequencyt analysis)
    - 기지 평문 공격(known plain text) : 이전에 사용된 평문과 암호 메세지 쌍을 입수
    - 선택 평문(chosen plain text) : 임의의 평문을 선택해 그 평문을 암호화 한 메시지를 입수
    - 좋은 알고리즘을 이러한 모든 공격을 견딜 수 있어야함.
- 모든 보안은 키에 달려있음

### 비밀 키 암호 기법(대칭키)

- 대칭키 암호 기법(symmetric-key cryptograhpy) : 같은 비밀키를 사용하여 암호화 복호화 진행
- 이 비밀 키는 메시지를 교환하고자 하는 모든 당사자에게 공유됨
- 2000년대 초반 IBM과 NSA가 개발한 DES(Data Encryption Standard, 데이터 암호화 표준)
    - 56비트키 사용. 컴퓨터의 처리 속도가 빨라짐에 따라 더 긴 키를 이용한 새로운 알고리즘 개발
- AES(Advanced Encryption Standard, 고급 암호화 표준)
    - NIST(미국국립표준기술연구소)에 의해 개발
    - 128, 192, 256비트의 세 가지 키 길이를 지원함
- 키 분배(key distribution) 의 문제. 통신 중인 각 당사자가 키를 알아야 하므로, 각자에게 전달할 방법이 있어야함.
- 키 확산(key proliferation)의 문제. 서로 관련 없는 여러 당사자들과 각각 은밀한 대화렬 하려면 각 그룹에 별도의 키가 필요하므로, 키 분배 문제가 어려워짐.